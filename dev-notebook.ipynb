{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc71373f",
   "metadata": {},
   "source": [
    "# Minimal working UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b1480",
   "metadata": {},
   "source": [
    "## 0. imports and data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc5b631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py # note: importing h5py multiple times can cause an error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch as t\n",
    "import torch.nn.functional as f\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a4309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/h5/train'\n",
    "os.listdir(train_dir)\n",
    "train_subjects = os.listdir(train_dir)\n",
    "train_subject = train_subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6077406e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 256, 256, 256), (102, 256, 256, 256))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_h5 = h5py.File(f'{train_dir}/{train_subject}', 'r')\n",
    "\n",
    "train_h5_raw_np = np.array(train_h5.get('raw'))\n",
    "train_h5_label_np = np.array(train_h5.get('label'))\n",
    "\n",
    "raw_shape = train_h5_raw_np.shape\n",
    "label_shape = train_h5_label_np.shape\n",
    "\n",
    "raw_shape, label_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2708154",
   "metadata": {},
   "source": [
    "## 1. Dataloader logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c0c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_subject_list = sorted(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8a6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "    \"\"\" A custom Dataset class to iterate over subjects.\n",
    "        This Dataset assumes that the data take the following form:\n",
    "            data_dir/\n",
    "                -- subject0.hdf5 (file with two datasets)\n",
    "                    -- x_name: 4D array\n",
    "                    -- y_name: 4D array\n",
    "                -- subject1.hdf5 (next file with two datasets)\n",
    "                    -- ...\n",
    "        Note also that this directory should not contain any other files\n",
    "        besides h5 files for subjects intended to be included in this dataset.\n",
    "        -----\n",
    "        Arguments:\n",
    "            data_dir\n",
    "            x_name\n",
    "            y_name\n",
    "            ordered_subject_list\n",
    "        -----       \n",
    "        Returns:\n",
    "            Pytorch index-based Dataset where each sample is an x, y pair of tensors\n",
    "                corresponding to a 3D T1 scan and a 4D set of anatomical labels (one-hot)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_dir, \n",
    "                 x_name=None,\n",
    "                 y_name=None,\n",
    "                 ordered_subject_list=None):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        # parse default args\n",
    "        x_name = 'raw' if x_name is None else x_name\n",
    "        y_name = 'label' if y_name is None else y_name\n",
    "        self.x_name = x_name\n",
    "        self.y_name = y_name\n",
    "        \n",
    "        # parse subject ordering, if specified\n",
    "        if ordered_subject_list is None:\n",
    "            ordered_subject_list = sorted(os.listdir(data_dir))\n",
    "        self.subjects = ordered_subject_list\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        subject = self.subjects[index]  # Select the current datapoint (subject)    \n",
    "        h5 = h5py.File(f'{self.data_dir}/{subject}', 'r')\n",
    "        \n",
    "        x_np = h5.get(self.x_name)\n",
    "        y_np = h5.get(self.y_name)\n",
    "        \n",
    "        x = t.from_numpy(np.array(x_np))\n",
    "        y = t.from_numpy(np.array(y_np))\n",
    "        \n",
    "        h5.close() # close the h5 file to avoid extra memory usage\n",
    "\n",
    "        # If necessary, apply any preprocessing or transformations to the data\n",
    "        # data = ...\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48ca6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HDF5Dataset(data_dir=train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, yt = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8f9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e51a8f47",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f97a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch3dunet.unet3d.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch3dunet.unet3d.buildingblocks import DoubleConv, ResNetBlock, ResNetBlockSE, \\\n",
    "    create_decoders, create_encoders\n",
    "from pytorch3dunet.unet3d.utils import get_class, number_of_features_per_level\n",
    "\n",
    "\n",
    "class AbstractUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output segmentation masks;\n",
    "            Note that the of out_channels might correspond to either\n",
    "            different semantic classes or to different binary segmentation mask.\n",
    "            It's up to the user of the class to interpret the out_channels and\n",
    "            use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)\n",
    "            or BCEWithLogitsLoss (two-class) respectively)\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the final 1x1 convolution,\n",
    "            otherwise apply nn.Softmax. In effect only if `self.training == False`, i.e. during validation/testing\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers in `SingleConv` module.\n",
    "            E.g. 'crg' stands for GroupNorm3d+Conv3d+ReLU. See `SingleConv` for more info\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "            default: 4\n",
    "        is_segmentation (bool): if True and the model is in eval mode, Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        is3d (bool): if True the model is 3D, otherwise 2D, default: True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_kernel_size=3, pool_kernel_size=2,\n",
    "                 conv_padding=1, is3d=True):\n",
    "        super(AbstractUNet, self).__init__()\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
    "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
    "        if 'g' in layer_order:\n",
    "            assert num_groups is not None, \"num_groups must be specified if GroupNorm is used\"\n",
    "\n",
    "        # create encoder path\n",
    "        self.encoders = create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order,\n",
    "                                        num_groups, pool_kernel_size, is3d)\n",
    "\n",
    "        # create decoder path\n",
    "        self.decoders = create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
    "                                        is3d)\n",
    "\n",
    "        # in the last layer a 1Ã—1 convolution reduces the number of output channels to the number of labels\n",
    "        if is3d:\n",
    "            self.final_conv = nn.Conv3d(f_maps[0], out_channels, 1)\n",
    "        else:\n",
    "            self.final_conv = nn.Conv2d(f_maps[0], out_channels, 1)\n",
    "\n",
    "        if is_segmentation:\n",
    "            # semantic segmentation problem\n",
    "            if final_sigmoid:\n",
    "                self.final_activation = nn.Sigmoid()\n",
    "            else:\n",
    "                self.final_activation = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            # regression problem\n",
    "            self.final_activation = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction.\n",
    "        # During training the network outputs logits\n",
    "        if not self.training and self.final_activation is not None:\n",
    "            x = self.final_activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet3D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv,\n",
    "                                     f_maps=f_maps,\n",
    "                                     layer_order=layer_order,\n",
    "                                     num_groups=num_groups,\n",
    "                                     num_levels=num_levels,\n",
    "                                     is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding,\n",
    "                                     is3d=True)\n",
    "\n",
    "\n",
    "class ResidualUNet3D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    Residual 3DUnet model implementation based on https://arxiv.org/pdf/1706.00120.pdf.\n",
    "    Uses ResNetBlock as a basic building block, summation joining instead\n",
    "    of concatenation joining and transposed convolutions for upsampling (watch out for block artifacts).\n",
    "    Since the model effectively becomes a residual net, in theory it allows for deeper UNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=5, is_segmentation=True, conv_padding=1, **kwargs):\n",
    "        super(ResidualUNet3D, self).__init__(in_channels=in_channels,\n",
    "                                             out_channels=out_channels,\n",
    "                                             final_sigmoid=final_sigmoid,\n",
    "                                             basic_module=ResNetBlock,\n",
    "                                             f_maps=f_maps,\n",
    "                                             layer_order=layer_order,\n",
    "                                             num_groups=num_groups,\n",
    "                                             num_levels=num_levels,\n",
    "                                             is_segmentation=is_segmentation,\n",
    "                                             conv_padding=conv_padding,\n",
    "                                             is3d=True)\n",
    "\n",
    "\n",
    "class ResidualUNetSE3D(AbstractUNet):\n",
    "    \"\"\"_summary_\n",
    "    Residual 3DUnet model implementation with squeeze and excitation based on \n",
    "    https://arxiv.org/pdf/1706.00120.pdf.\n",
    "    Uses ResNetBlockSE as a basic building block, summation joining instead\n",
    "    of concatenation joining and transposed convolutions for upsampling (watch\n",
    "    out for block artifacts). Since the model effectively becomes a residual\n",
    "    net, in theory it allows for deeper UNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=5, is_segmentation=True, conv_padding=1, **kwargs):\n",
    "        super(ResidualUNetSE3D, self).__init__(in_channels=in_channels,\n",
    "                                               out_channels=out_channels,\n",
    "                                               final_sigmoid=final_sigmoid,\n",
    "                                               basic_module=ResNetBlockSE,\n",
    "                                               f_maps=f_maps,\n",
    "                                               layer_order=layer_order,\n",
    "                                               num_groups=num_groups,\n",
    "                                               num_levels=num_levels,\n",
    "                                               is_segmentation=is_segmentation,\n",
    "                                               conv_padding=conv_padding,\n",
    "                                               is3d=True)\n",
    "\n",
    "\n",
    "class UNet2D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    2DUnet model from\n",
    "    `\"U-Net: Convolutional Networks for Biomedical Image Segmentation\" <https://arxiv.org/abs/1505.04597>`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
    "        super(UNet2D, self).__init__(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv,\n",
    "                                     f_maps=f_maps,\n",
    "                                     layer_order=layer_order,\n",
    "                                     num_groups=num_groups,\n",
    "                                     num_levels=num_levels,\n",
    "                                     is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding,\n",
    "                                     is3d=False)\n",
    "\n",
    "\n",
    "def get_model(model_config):\n",
    "    model_class = get_class(model_config['name'], modules=[\n",
    "        'pytorch3dunet.unet3d.model'\n",
    "    ])\n",
    "    return model_class(**model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e3fb4",
   "metadata": {},
   "source": [
    "## 3. Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678722d6",
   "metadata": {},
   "source": [
    "## 4. Evaluation, visualizaitons, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3722b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-ni-ny]",
   "language": "python",
   "name": "conda-env-torch-ni-ny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
